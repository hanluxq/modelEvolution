{"cells":[{"cell_type":"code","source":["!pip install transformers seqeval shap scikit-learn"],"metadata":{"id":"kbqnpqGWQBW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import transformers\n","import sys\n","import os"],"metadata":{"id":"0TIuwWNCPjBr","executionInfo":{"status":"ok","timestamp":1685624431558,"user_tz":-480,"elapsed":7135,"user":{"displayName":"lu han","userId":"00064302419450254877"}}}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7WCJup8fQbl5","executionInfo":{"status":"ok","timestamp":1685624465764,"user_tz":-480,"elapsed":24221,"user":{"displayName":"lu han","userId":"00064302419450254877"}},"outputId":"7a0fd06b-f46b-463a-fa87-25fdaf5b4dd9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## 加载模型"],"metadata":{"collapsed":false,"id":"fIcUhT28PjBt"}},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":true,"id":"c9AffX37PjBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685625564914,"user_tz":-480,"elapsed":2592,"user":{"displayName":"lu han","userId":"00064302419450254877"}},"outputId":"519315c2-00e6-45ed-87ef-7c6bebeebfe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":20}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model_name = 'bert-base-uncased' # 预训练模型名字\n","tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n","model = transformers.BertForSequenceClassification.from_pretrained(model_name, num_labels=2) # 需要预测的类别数为2\n","os.chdir('/content/drive/MyDrive/ModelDebug/classifier/baseline')\n","model_weights = torch.load('./pytorch_model.bin')\n","model.load_state_dict(model_weights)\n","model.eval()\n","model.to(device)"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# 读取CSV文件\n","df = pd.read_csv('./expand.csv')\n","\n","# 获取文本数据列和标签列\n","texts = df['RequirementText'].tolist()\n","labels = df['NFR'].tolist()\n","\n","# 将标签转换为整数类型\n","labels = [int(label) for label in labels]\n","\n","# 创建真实标签列表和预测标签列表\n","true_labels = labels\n","predicted_labels = []\n","\n","# 遍历数据集进行预测\n","for text in texts:\n","    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n","    inputs = inputs.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    logits = outputs.logits\n","    probabilities = torch.softmax(logits, dim=1)\n","    predicted_label = torch.argmax(probabilities, dim=1).item()\n","    predicted_labels.append(predicted_label)\n","\n","# 将真实标签和预测标签移动到相同的设备上\n","true_labels = torch.tensor(true_labels).to(device)\n","predicted_labels = torch.tensor(predicted_labels).to(device)\n","\n","# 计算指标\n","precision = precision_score(true_labels.cpu(), predicted_labels.cpu())\n","recall = recall_score(true_labels.cpu(), predicted_labels.cpu())\n","f1 = f1_score(true_labels.cpu(), predicted_labels.cpu())\n","\n","# 输出指标结果\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0lvkV2E7rLg","executionInfo":{"status":"ok","timestamp":1685625580725,"user_tz":-480,"elapsed":4662,"user":{"displayName":"lu han","userId":"00064302419450254877"}},"outputId":"28b421b0-d523-4598-9da7-b61e0ff4381c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.6894736842105263\n","Recall: 0.9097222222222222\n","F1 Score: 0.7844311377245509\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}